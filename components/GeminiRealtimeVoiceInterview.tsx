'use client'

import { useState, useEffect, useRef, useCallback } from 'react'

interface GeminiRealtimeVoiceInterviewProps {
  sessionNumber: number
  onConversationSave: (question: string, answer: string) => Promise<void>
}

interface Conversation {
  role: 'user' | 'assistant'
  content: string
  timestamp: Date
  audioComplete?: boolean
}

export default function GeminiRealtimeVoiceInterview({ 
  sessionNumber, 
  onConversationSave 
}: GeminiRealtimeVoiceInterviewProps) {
  const [isConnected, setIsConnected] = useState(false)
  const [isRecording, setIsRecording] = useState(false)
  const [conversations, setConversations] = useState<Conversation[]>([])
  const [connectionStatus, setConnectionStatus] = useState('ì—°ê²° ì¤€ë¹„ ì¤‘...')
  const [isAISpeaking, setIsAISpeaking] = useState(false)

  // Refs
  const sessionRef = useRef<any>(null)
  const audioStreamRef = useRef<MediaStream | null>(null)
  const audioContextRef = useRef<AudioContext | null>(null)
  const processorRef = useRef<ScriptProcessorNode | null>(null)
  const geminiClientRef = useRef<any>(null)

  useEffect(() => {
    // í´ë¼ì´ì–¸íŠ¸ ì‚¬ì´ë“œì—ì„œë§Œ ì´ˆê¸°í™”
    if (typeof window !== 'undefined') {
      initializeGeminiLive()
    }

    return () => {
      disconnect()
    }
  }, [sessionNumber])

  const initializeGeminiLive = async () => {
    try {
      setConnectionStatus('Gemini Live API ì´ˆê¸°í™” ì¤‘...')
      
      // ë¸Œë¼ìš°ì € í˜¸í™˜ì„± í™•ì¸
      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        throw new Error('ì´ ë¸Œë¼ìš°ì €ëŠ” ë§ˆì´í¬ ì ‘ê·¼ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.')
      }

      setConnectionStatus('API ì„¤ì • ë¡œë”© ì¤‘...')
    } catch (error) {
      console.error('ì´ˆê¸°í™” ì˜¤ë¥˜:', error)
      setConnectionStatus(`ì´ˆê¸°í™” ì‹¤íŒ¨: ${error instanceof Error ? error.message : 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'}`)
    }
  }

  const connectToGemini = useCallback(async () => {
    try {
      setConnectionStatus('Gemini Live API ì—°ê²° ì¤‘...')

      // API ì„¤ì • ê°€ì ¸ì˜¤ê¸°
      const configResponse = await fetch(`/api/gemini/live-websocket?sessionNumber=${sessionNumber}`)
      if (!configResponse.ok) {
        throw new Error('API ì„¤ì • ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨')
      }
      const config = await configResponse.json()

      // Dynamic importë¡œ Gemini SDK ë¡œë“œ
      const { GoogleGenAI } = await import('@google/genai')
      
      // Gemini AI ì´ˆê¸°í™”
      const genAI = new GoogleGenAI({ apiKey: config.apiKey })
      geminiClientRef.current = genAI
      
      console.log('Gemini Live ì—°ê²° ì‹œë„:', config.model)
      
      // Live API ì—°ê²°
      const session = await genAI.live.connect({
        model: config.model,
        config: {
          responseModalities: ["AUDIO"],
          systemInstruction: config.sessionPrompt
        },
        callbacks: {
          onopen: () => {
            console.log('Gemini Live ì—°ê²° ì„±ê³µ')
            setIsConnected(true)
            setConnectionStatus('ìŒì„± ì¸í„°ë·° ì¤€ë¹„ ì™„ë£Œ')
            // ìë™ ë…¹ìŒ ì‹œì‘í•˜ì§€ ì•Šê³  ìˆ˜ë™ìœ¼ë¡œ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆê²Œ í•¨
          },
          onmessage: (message: any) => {
            console.log('Gemini Live ë©”ì‹œì§€:', message)
            handleGeminiMessage(message)
          },
          onerror: (error: any) => {
            console.error('Gemini Live ì˜¤ë¥˜:', error)
            setConnectionStatus(`ì—°ê²° ì˜¤ë¥˜: ${error.message || 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'}`)
            setIsConnected(false)
          },
          onclose: (reason: any) => {
            console.log('Gemini Live ì—°ê²° ì¢…ë£Œ:', reason)
            setIsConnected(false)
            setConnectionStatus('ì—°ê²° ì¢…ë£Œë¨')
          }
        }
      })

      sessionRef.current = session

      // ì˜¤ë””ì˜¤ ì„¤ì •
      await setupAudioCapture()

    } catch (error) {
      console.error('Gemini ì—°ê²° ì˜¤ë¥˜:', error)
      setConnectionStatus(`ì—°ê²° ì‹¤íŒ¨: ${error instanceof Error ? error.message : 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'}`)
    }
  }, [sessionNumber])

  const setupAudioCapture = async () => {
    try {
      // ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate: 16000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true
        }
      })
      
      audioStreamRef.current = stream

      // AudioContext ì„¤ì •
      const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)({
        sampleRate: 16000
      })
      audioContextRef.current = audioContext

      const source = audioContext.createMediaStreamSource(stream)
      const processor = audioContext.createScriptProcessor(1024, 1, 1)
      processorRef.current = processor

      processor.onaudioprocess = (event) => {
        if (isRecording && sessionRef.current) {
          const inputBuffer = event.inputBuffer.getChannelData(0)
          
          // ì˜¤ë””ì˜¤ ë ˆë²¨ í™•ì¸ (ì†Œë¦¬ê°€ ë“¤ì–´ì˜¤ëŠ”ì§€ ì²´í¬)
          const audioLevel = Math.max(...inputBuffer.map(Math.abs))
          if (audioLevel > 0.01) {
            console.log('ì˜¤ë””ì˜¤ ê°ì§€ë¨, ë ˆë²¨:', audioLevel.toFixed(4))
          }
          
          // Float32 to Int16 conversion
          const pcmData = float32ToInt16(inputBuffer)
          
          // Gemini Live APIì— ì˜¤ë””ì˜¤ ë°ì´í„° ì „ì†¡
          sendAudioToGemini(pcmData)
        }
      }

      source.connect(processor)
      processor.connect(audioContext.destination)

    } catch (error) {
      console.error('ì˜¤ë””ì˜¤ ì„¤ì • ì˜¤ë¥˜:', error)
      setConnectionStatus('ë§ˆì´í¬ ì ‘ê·¼ ì‹¤íŒ¨')
    }
  }

  // Float32Arrayë¥¼ Int16Arrayë¡œ ë³€í™˜
  const float32ToInt16 = (float32Array: Float32Array): Int16Array => {
    const int16Array = new Int16Array(float32Array.length)
    for (let i = 0; i < float32Array.length; i++) {
      const val = Math.max(-1, Math.min(1, float32Array[i]))
      int16Array[i] = val < 0 ? val * 0x8000 : val * 0x7FFF
    }
    return int16Array
  }

  const sendAudioToGemini = async (audioData: Int16Array) => {
    if (!sessionRef.current) {
      console.log('ì„¸ì…˜ì´ ì—†ìŒ, ì˜¤ë””ì˜¤ ì „ì†¡ ê±´ë„ˆëœ€')
      return
    }
    
    try {
      // Int16Arrayë¥¼ ArrayBufferë¡œ ë³€í™˜í•˜ì—¬ Blob ìƒì„±
      const audioBlob = new Blob([audioData.buffer], { type: "audio/pcm;rate=16000" })
      
      // ì „ì†¡ ë¡œê·¸
      console.log('ì˜¤ë””ì˜¤ ì „ì†¡ ì¤‘...', {
        í¬ê¸°: audioData.length,
        ë°”ì´íŠ¸: audioData.buffer.byteLength,
        ë¸”ë¡­í¬ê¸°: audioBlob.size
      })
      
      // Gemini Live APIì— ì˜¤ë””ì˜¤ ì „ì†¡ (Blob ë°©ì‹)
      await sessionRef.current.sendRealtimeInput({
        audio: audioBlob
      })
      
      console.log('ì˜¤ë””ì˜¤ ì „ì†¡ ì™„ë£Œ')
    } catch (error) {
      console.error('ì˜¤ë””ì˜¤ ì „ì†¡ ì˜¤ë¥˜:', error)
      
      // ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ì¬ì‹œë„
      try {
        console.log('ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ì¬ì‹œë„...')
        const bytes = new Uint8Array(audioData.buffer)
        const base64Audio = btoa(String.fromCharCode.apply(null, Array.from(bytes)))
        
        await sessionRef.current.sendRealtimeInput({
          audio: {
            data: base64Audio,
            mimeType: "audio/pcm;rate=16000"
          }
        })
        console.log('ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ì „ì†¡ ì„±ê³µ')
      } catch (retryError) {
        console.error('ì¬ì‹œë„ë„ ì‹¤íŒ¨:', retryError)
      }
    }
  }

  const handleGeminiMessage = useCallback((message: any) => {
    console.log('Gemini ì‘ë‹µ:', message)
    
    // ì„¤ì • ì™„ë£Œ ì‹œ ì´ˆê¸° ì¸ì‚¬
    if (message.setupComplete) {
      console.log('Gemini Live ì„¤ì • ì™„ë£Œ!')
      setTimeout(() => {
        if (sessionRef.current) {
          console.log('ì´ˆê¸° í…ìŠ¤íŠ¸ ë©”ì‹œì§€ ì „ì†¡ í…ŒìŠ¤íŠ¸')
          sessionRef.current.sendClientContent({
            turns: [{ role: "user", parts: [{ text: "ì•ˆë…•í•˜ì„¸ìš”! ìŒì„± ì¸í„°ë·°ë¥¼ ì‹œì‘í•´ì£¼ì„¸ìš”." }] }],
            turnComplete: true
          }).then(() => {
            console.log('í…ìŠ¤íŠ¸ ë©”ì‹œì§€ ì „ì†¡ ì„±ê³µ')
          }).catch((error: any) => {
            console.error('ì´ˆê¸° ë©”ì‹œì§€ ì „ì†¡ ì˜¤ë¥˜:', error)
          })
        }
      }, 1000)
      return
    }
    
    // ì„œë²„ ì‘ë‹µ ì²˜ë¦¬
    if (message.serverContent) {
      const content = message.serverContent
      
      // ì…ë ¥ ì „ì‚¬ (ì‚¬ìš©ì ìŒì„± â†’ í…ìŠ¤íŠ¸)
      if (content.inputTranscription) {
        console.log('ì‚¬ìš©ì ìŒì„± ì „ì‚¬:', content.inputTranscription.text)
        const userMessage: Conversation = {
          role: 'user',
          content: content.inputTranscription.text,
          timestamp: new Date()
        }
        setConversations(prev => [...prev, userMessage])
      }
      
      // í…ìŠ¤íŠ¸ ì‘ë‹µ ì²˜ë¦¬
      if (content.modelTurn && content.modelTurn.parts) {
        for (const part of content.modelTurn.parts) {
          if (part.text) {
            console.log('AI í…ìŠ¤íŠ¸ ì‘ë‹µ:', part.text)
            const assistantMessage: Conversation = {
              role: 'assistant',
              content: part.text,
              timestamp: new Date(),
              audioComplete: true
            }
            setConversations(prev => [...prev, assistantMessage])
            
            // ëŒ€í™” ì €ì¥
            onConversationSave('AI ì§ˆë¬¸', part.text).catch(console.error)
          }
          
          // ì˜¤ë””ì˜¤ ì‘ë‹µ ì²˜ë¦¬
          if (part.inlineData && part.inlineData.mimeType === 'audio/pcm') {
            console.log('AI ì˜¤ë””ì˜¤ ì‘ë‹µ ìˆ˜ì‹ ')
            try {
              playAudioData(part.inlineData.data)
              setIsAISpeaking(true)
            } catch (error) {
              console.error('ì˜¤ë””ì˜¤ ì¬ìƒ ì˜¤ë¥˜:', error)
            }
          }
        }
      }
      
      // ì¶œë ¥ ì „ì‚¬ (AI ìŒì„± â†’ í…ìŠ¤íŠ¸)
      if (content.outputTranscription) {
        console.log('AI ìŒì„± ì „ì‚¬:', content.outputTranscription.text)
      }
      
      // í„´ ì™„ë£Œ ì²˜ë¦¬
      if (content.turnComplete) {
        console.log('í„´ ì™„ë£Œ')
        setIsAISpeaking(false)
      }
      
      // ì¸í„°ëŸ½íŠ¸ ì²˜ë¦¬
      if (content.interrupted) {
        console.log('AI ì‘ë‹µ ì¸í„°ëŸ½íŠ¸ë¨')
        setIsAISpeaking(false)
      }
    }
  }, [onConversationSave])

  const playAudioData = (base64AudioData: string) => {
    if (!audioContextRef.current) return

    try {
      // Base64 ë””ì½”ë”©
      const binaryString = atob(base64AudioData)
      const bytes = new Uint8Array(binaryString.length)
      for (let i = 0; i < binaryString.length; i++) {
        bytes[i] = binaryString.charCodeAt(i)
      }
      const int16Data = new Int16Array(bytes.buffer)
      
      // Int16 to Float32 ë³€í™˜
      const floatData = new Float32Array(int16Data.length)
      for (let i = 0; i < int16Data.length; i++) {
        floatData[i] = int16Data[i] / (int16Data[i] < 0 ? 0x8000 : 0x7FFF)
      }
      
      // ì˜¤ë””ì˜¤ ë²„í¼ ìƒì„± ë° ì¬ìƒ (24kHz)
      const audioContext = audioContextRef.current
      const audioBuffer = audioContext.createBuffer(1, floatData.length, 24000)
      audioBuffer.getChannelData(0).set(floatData)

      const source = audioContext.createBufferSource()
      source.buffer = audioBuffer
      source.connect(audioContext.destination)
      source.start()
      
      source.onended = () => {
        setIsAISpeaking(false)
      }
    } catch (error) {
      console.error('ì˜¤ë””ì˜¤ ì¬ìƒ ì‹¤íŒ¨:', error)
    }
  }

  const startRecording = () => {
    if (!isConnected) {
      console.log('ì—°ê²°ë˜ì§€ ì•ŠìŒ, ë…¹ìŒ ì‹œì‘ ë¶ˆê°€')
      return
    }
    
    setIsRecording(true)
    setConnectionStatus('ìŒì„± ë…¹ìŒ ì¤‘...')
  }

  const stopRecording = () => {
    setIsRecording(false)
    setConnectionStatus('ìŒì„± ì¸í„°ë·° ì¤€ë¹„ ì™„ë£Œ')
  }

  const sendTestMessage = async () => {
    if (!sessionRef.current) {
      console.log('ì„¸ì…˜ì´ ì—†ì–´ì„œ í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€ ì „ì†¡ ë¶ˆê°€')
      return
    }

    try {
      console.log('í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€ ì „ì†¡ ì¤‘...')
      await sessionRef.current.sendClientContent({
        turns: [{ role: "user", parts: [{ text: "ì•ˆë…•í•˜ì„¸ìš”! ì €ì— ëŒ€í•´ ê°„ë‹¨íˆ ì†Œê°œí•´ì£¼ì„¸ìš”." }] }],
        turnComplete: true
      })
      console.log('í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€ ì „ì†¡ ì™„ë£Œ')
    } catch (error) {
      console.error('í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€ ì „ì†¡ ì˜¤ë¥˜:', error)
    }
  }

  const disconnect = useCallback(async () => {
    console.log('Gemini Live ì—°ê²° í•´ì œ ì¤‘...')

    // Gemini Live ì„¸ì…˜ í•´ì œ
    if (sessionRef.current) {
      try {
        sessionRef.current.close()
      } catch (error) {
        console.error('Gemini Live ì„¸ì…˜ ì¢…ë£Œ ì˜¤ë¥˜:', error)
      }
      sessionRef.current = null
    }

    // ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ í•´ì œ
    if (audioStreamRef.current) {
      audioStreamRef.current.getTracks().forEach(track => track.stop())
      audioStreamRef.current = null
    }

    // AudioContext í•´ì œ
    if (audioContextRef.current) {
      audioContextRef.current.close()
      audioContextRef.current = null
    }

    // Processor í•´ì œ
    if (processorRef.current) {
      processorRef.current.disconnect()
      processorRef.current = null
    }

    setIsConnected(false)
    setIsRecording(false)
    setIsAISpeaking(false)
    setConnectionStatus('ì—°ê²° í•´ì œë¨')
  }, [])

  const isMobile = typeof window !== 'undefined' && navigator.userAgent.match(/iPhone|iPad|iPod|Android/i)

  return (
    <div className="bg-white rounded-lg shadow-lg p-4 sm:p-6">
      <div className="mb-4 sm:mb-6">
        <h3 className="text-lg sm:text-xl font-semibold text-gray-800 mb-2">
          ğŸ¤ Gemini Live ì‹¤ì‹œê°„ ìŒì„± ì¸í„°ë·°
        </h3>
        <p className="text-sm sm:text-base text-gray-600 mb-2">{connectionStatus}</p>
        <p className="text-xs text-gray-500">
          Googleì˜ ìµœì‹  Gemini 2.5 Flash Native Audio Dialog ëª¨ë¸ê³¼ ì‹¤ì‹œê°„ ìŒì„± ëŒ€í™”ë¥¼ ë‚˜ëˆ„ì„¸ìš”
        </p>
        {isMobile && (
          <p className="text-xs sm:text-sm text-amber-600 mt-2">
            ğŸ“± ëª¨ë°”ì¼ í™˜ê²½ì…ë‹ˆë‹¤. Chrome ë˜ëŠ” Safari ë¸Œë¼ìš°ì € ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤.
          </p>
        )}
      </div>

      {/* ì—°ê²° ìƒíƒœ í‘œì‹œ */}
      <div className="flex items-center justify-center mb-4 sm:mb-6">
        <div className={`w-3 h-3 rounded-full mr-2 ${isConnected ? 'bg-green-500 animate-pulse' : 'bg-red-500'}`}></div>
        <span className="text-sm text-gray-600">
          {isConnected ? 'ì—°ê²°ë¨' : 'ì—°ê²° ì•ˆë¨'}
        </span>
      </div>

      {/* ìŒì„± ì¸í„°ë·° ì»¨íŠ¸ë¡¤ */}
      <div className="flex flex-col items-center gap-4 mb-6">
        {!isConnected ? (
          <button
            onClick={connectToGemini}
            className="bg-blue-600 hover:bg-blue-700 text-white font-bold py-3 px-6 rounded-lg text-lg transition-colors"
          >
            ğŸ¤ Gemini Live ì—°ê²°
          </button>
        ) : (
          <div className="flex flex-col gap-3">
            {/* í…ìŠ¤íŠ¸ í…ŒìŠ¤íŠ¸ ë²„íŠ¼ */}
            <button
              onClick={sendTestMessage}
              disabled={isAISpeaking}
              className="bg-purple-600 hover:bg-purple-700 disabled:bg-purple-400 text-white font-bold py-2 px-4 rounded-lg transition-colors"
            >
              ğŸ’¬ í…ìŠ¤íŠ¸ ë©”ì‹œì§€ í…ŒìŠ¤íŠ¸ (AIê°€ ìŒì„±ìœ¼ë¡œ ì‘ë‹µ)
            </button>
            
            {/* ìŒì„± ë…¹ìŒ ì»¨íŠ¸ë¡¤ */}
            <div className="flex gap-4">
              <button
                onClick={startRecording}
                disabled={isRecording || isAISpeaking}
                className={`font-bold py-3 px-6 rounded-lg text-lg transition-colors ${
                  isRecording 
                    ? 'bg-red-600 text-white cursor-not-allowed' 
                    : 'bg-green-600 hover:bg-green-700 text-white'
                }`}
              >
                {isRecording ? 'ğŸ”´ ë…¹ìŒ ì¤‘...' : 'ğŸ™ï¸ ìŒì„± ë…¹ìŒ ì‹œì‘'}
              </button>
              <button
                onClick={stopRecording}
                disabled={!isRecording}
                className="bg-gray-600 hover:bg-gray-700 disabled:bg-gray-400 text-white font-bold py-3 px-6 rounded-lg text-lg transition-colors"
              >
                â¹ï¸ ë…¹ìŒ ì¤‘ë‹¨
              </button>
            </div>
          </div>
        )}
      </div>

      {/* AI ì‘ë‹µ ìƒíƒœ */}
      {isAISpeaking && (
        <div className="text-center mb-4">
          <div className="inline-flex items-center px-4 py-2 bg-blue-100 rounded-lg">
            <div className="animate-spin rounded-full h-4 w-4 border-b-2 border-blue-600 mr-2"></div>
            <span className="text-blue-800 text-sm">AIê°€ ì‘ë‹µ ì¤‘ì…ë‹ˆë‹¤...</span>
          </div>
        </div>
      )}

      {/* ëŒ€í™” ë‚´ìš© */}
      {conversations.length > 0 && (
        <div className="bg-gray-50 rounded-lg p-4 max-h-60 overflow-y-auto">
          <h4 className="font-semibold text-gray-700 mb-3">ì‹¤ì‹œê°„ ëŒ€í™” ë‚´ìš©</h4>
          <div className="space-y-3">
            {conversations.map((conv, index) => (
              <div key={index} className={`flex ${conv.role === 'user' ? 'justify-end' : 'justify-start'}`}>
                <div className={`max-w-[80%] p-3 rounded-lg ${
                  conv.role === 'user' 
                    ? 'bg-blue-600 text-white' 
                    : 'bg-white text-gray-800 border'
                }`}>
                  <p className="text-sm">{conv.content}</p>
                  <p className="text-xs opacity-70 mt-1">
                    {conv.timestamp.toLocaleTimeString()}
                  </p>
                </div>
              </div>
            ))}
          </div>
        </div>
      )}

      {/* ë„ì›€ë§ */}
      <div className="mt-6 text-xs text-gray-500">
        <p className="mb-2">ğŸ’¡ í…ŒìŠ¤íŠ¸ ìˆœì„œ:</p>
        <ul className="list-disc list-inside space-y-1 ml-2">
          <li>â€¢ 1ë‹¨ê³„: "Gemini Live ì—°ê²°" ë²„íŠ¼ìœ¼ë¡œ ì—°ê²°</li>
          <li>â€¢ 2ë‹¨ê³„: "í…ìŠ¤íŠ¸ ë©”ì‹œì§€ í…ŒìŠ¤íŠ¸" ë²„íŠ¼ìœ¼ë¡œ AI ìŒì„± ì‘ë‹µ í™•ì¸</li>
          <li>â€¢ 3ë‹¨ê³„: "ìŒì„± ë…¹ìŒ ì‹œì‘" ë²„íŠ¼ìœ¼ë¡œ ìŒì„± ì…ë ¥ í…ŒìŠ¤íŠ¸</li>
          <li>â€¢ ë¸Œë¼ìš°ì €ê°€ ë§ˆì´í¬ ê¶Œí•œì„ ìš”ì²­í•˜ë©´ í—ˆìš©í•´ì£¼ì„¸ìš”</li>
          <li>â€¢ ì½˜ì†” ë¡œê·¸ì—ì„œ ìƒì„¸í•œ ì§„í–‰ ìƒí™©ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤</li>
        </ul>
      </div>
    </div>
  )
}
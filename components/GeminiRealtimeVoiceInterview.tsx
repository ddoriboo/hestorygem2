'use client'

import { useState, useEffect, useRef, useCallback } from 'react'

interface GeminiRealtimeVoiceInterviewProps {
  sessionNumber: number
  onConversationSave: (question: string, answer: string) => Promise<void>
}

interface Conversation {
  role: 'user' | 'assistant'
  content: string
  timestamp: Date
  audioComplete?: boolean
}

export default function GeminiRealtimeVoiceInterview({ 
  sessionNumber, 
  onConversationSave 
}: GeminiRealtimeVoiceInterviewProps) {
  const [isConnected, setIsConnected] = useState(false)
  const [isRecording, setIsRecording] = useState(false)
  const [conversations, setConversations] = useState<Conversation[]>([])
  const [connectionStatus, setConnectionStatus] = useState('ì—°ê²° ì¤€ë¹„ ì¤‘...')
  const [isAISpeaking, setIsAISpeaking] = useState(false)
  const [audioLevel, setAudioLevel] = useState(0)
  const [voiceDetected, setVoiceDetected] = useState(false)
  const [processorActive, setProcessorActive] = useState(false)

  // Refs
  const sessionRef = useRef<any>(null)
  const audioStreamRef = useRef<MediaStream | null>(null)
  const audioContextRef = useRef<AudioContext | null>(null)
  const processorRef = useRef<ScriptProcessorNode | null>(null)
  const analyserRef = useRef<AnalyserNode | null>(null)
  const mediaRecorderRef = useRef<MediaRecorder | null>(null)
  const geminiClientRef = useRef<any>(null)
  const responseQueueRef = useRef<any[]>([])
  const messageHandlersRef = useRef<((data: any) => void)[]>([])

  useEffect(() => {
    // í´ë¼ì´ì–¸íŠ¸ ì‚¬ì´ë“œì—ì„œë§Œ ì´ˆê¸°í™”
    if (typeof window !== 'undefined') {
      initializeGeminiLive()
      // ë§ˆì´í¬ ì„¤ì •ì„ ë…ë¦½ì ìœ¼ë¡œ ì´ˆê¸°í™”
      initializeAudioCapture()
    }

    return () => {
      disconnect()
    }
  }, [sessionNumber])

  const initializeGeminiLive = async () => {
    try {
      setConnectionStatus('Gemini Live API ì´ˆê¸°í™” ì¤‘...')
      
      // ë¸Œë¼ìš°ì € í˜¸í™˜ì„± í™•ì¸
      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        throw new Error('ì´ ë¸Œë¼ìš°ì €ëŠ” ë§ˆì´í¬ ì ‘ê·¼ì„ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.')
      }

      setConnectionStatus('API ì„¤ì • ë¡œë”© ì¤‘...')
    } catch (error) {
      console.error('ì´ˆê¸°í™” ì˜¤ë¥˜:', error)
      setConnectionStatus(`ì´ˆê¸°í™” ì‹¤íŒ¨: ${error instanceof Error ? error.message : 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'}`)
    }
  }

  const initializeAudioCapture = async () => {
    try {
      console.log('ğŸ¯ ë…ë¦½ì  ë§ˆì´í¬ ì´ˆê¸°í™” ì‹œì‘...')
      setConnectionStatus('ë§ˆì´í¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...')
      
      // ë¸Œë¼ìš°ì € ì§€ì› í™•ì¸
      if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
        throw new Error('ì´ ë¸Œë¼ìš°ì €ëŠ” ë§ˆì´í¬ë¥¼ ì§€ì›í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.')
      }
      
      console.log('âœ… ë¸Œë¼ìš°ì € ë§ˆì´í¬ ì§€ì› í™•ì¸ë¨')
      
      // HTTPS í™•ì¸ (ë³´ì•ˆ ì»¨í…ìŠ¤íŠ¸)
      if (location.protocol !== 'https:' && location.hostname !== 'localhost') {
        console.warn('âš ï¸ HTTPSê°€ ì•„ë‹Œ í™˜ê²½ì—ì„œëŠ” ë§ˆì´í¬ ì ‘ê·¼ì´ ì œí•œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.')
      }
      
      console.log('ğŸŒ í˜„ì¬ URL:', location.href)
      console.log('ğŸ”’ ë³´ì•ˆ ì»¨í…ìŠ¤íŠ¸:', window.isSecureContext)
      
      setConnectionStatus('ë§ˆì´í¬ ì´ˆê¸°í™” ì™„ë£Œ')
      console.log('âœ… ë§ˆì´í¬ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ!')
      
    } catch (error) {
      console.error('âŒ ë§ˆì´í¬ ì´ˆê¸°í™” ì‹¤íŒ¨:', error)
      setConnectionStatus(`ë§ˆì´í¬ ì´ˆê¸°í™” ì‹¤íŒ¨: ${error instanceof Error ? error.message : 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'}`)
    }
  }

  // ê³µì‹ ì˜ˆì œ íŒ¨í„´: ë©”ì‹œì§€ ëŒ€ê¸° í•¨ìˆ˜
  const waitMessage = useCallback(async () => {
    let done = false
    let message = undefined
    while (!done) {
      message = responseQueueRef.current.shift()
      if (message) {
        done = true
      } else {
        await new Promise((resolve) => setTimeout(resolve, 100))
      }
    }
    return message
  }, [])

  // ê³µì‹ ì˜ˆì œ íŒ¨í„´: í„´ ì²˜ë¦¬ í•¨ìˆ˜
  const handleTurn = useCallback(async () => {
    const turns = []
    let done = false
    while (!done) {
      const message = await waitMessage()
      turns.push(message)
      if (message.serverContent && message.serverContent.turnComplete) {
        done = true
      }
    }
    return turns
  }, [waitMessage])

  const connectToGemini = useCallback(async () => {
    try {
      setConnectionStatus('Gemini Live API ì—°ê²° ì¤‘...')

      // API ì„¤ì • ê°€ì ¸ì˜¤ê¸°
      const configResponse = await fetch(`/api/gemini/live-websocket?sessionNumber=${sessionNumber}`)
      if (!configResponse.ok) {
        throw new Error('API ì„¤ì • ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨')
      }
      const config = await configResponse.json()

      // Dynamic importë¡œ Gemini SDK ë¡œë“œ
      const { GoogleGenAI, Modality } = await import('@google/genai')
      
      // Gemini AI ì´ˆê¸°í™”
      const genAI = new GoogleGenAI({ apiKey: config.apiKey })
      geminiClientRef.current = genAI
      
      console.log('Gemini Live ì—°ê²° ì‹œë„:', config.model)
      
      // ì‘ë‹µ í ì´ˆê¸°í™”
      responseQueueRef.current = []
      
      // Live API ì—°ê²° (ê³µì‹ ì˜ˆì œ íŒ¨í„´)
      const session = await genAI.live.connect({
        model: config.model,
        config: {
          responseModalities: [Modality.AUDIO],
          systemInstruction: config.sessionPrompt
        },
        callbacks: {
          onopen: () => {
            console.log('Gemini Live ì—°ê²° ì„±ê³µ')
            setIsConnected(true)
            setConnectionStatus('ìŒì„± ì¸í„°ë·° ì¤€ë¹„ ì™„ë£Œ')
          },
          onmessage: (message: any) => {
            console.log('Gemini Live ë©”ì‹œì§€:', message)
            // ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°ìš© ì¦‰ì‹œ ì²˜ë¦¬
            handleGeminiMessage(message)
          },
          onerror: (error: any) => {
            console.error('Gemini Live ì˜¤ë¥˜:', error)
            setConnectionStatus(`ì—°ê²° ì˜¤ë¥˜: ${error.message || 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'}`)
            setIsConnected(false)
          },
          onclose: (reason: any) => {
            console.log('Gemini Live ì—°ê²° ì¢…ë£Œ:', reason)
            setIsConnected(false)
            setConnectionStatus('ì—°ê²° ì¢…ë£Œë¨')
          }
        }
      })

      sessionRef.current = session

      // ë§ˆì´í¬ ì„¤ì •ì€ ë…ë¦½ì ìœ¼ë¡œ ì´ë¯¸ ì´ˆê¸°í™”ë˜ì—ˆìœ¼ë¯€ë¡œ ì œê±°
      console.log('ğŸ¤ Gemini ì—°ê²° ì™„ë£Œ, ë§ˆì´í¬ëŠ” ë…ë¦½ì ìœ¼ë¡œ ê´€ë¦¬ë¨')

    } catch (error) {
      console.error('Gemini ì—°ê²° ì˜¤ë¥˜:', error)
      setConnectionStatus(`ì—°ê²° ì‹¤íŒ¨: ${error instanceof Error ? error.message : 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜'}`)
    }
  }, [sessionNumber])

  const setupAudioCapture = async () => {
    try {
      console.log('ğŸ™ï¸ =================================')
      console.log('ğŸ™ï¸ ì˜¤ë””ì˜¤ ìº¡ì²˜ ì„¤ì • ì‹œì‘!')
      console.log('ğŸ™ï¸ =================================')
      
      // ì´ë¯¸ ì„¤ì •ë˜ì–´ ìˆë‹¤ë©´ ì •ë¦¬ í›„ ì¬ì„¤ì •
      if (audioStreamRef.current || audioContextRef.current || analyserRef.current || processorRef.current) {
        console.log('ğŸ”„ ê¸°ì¡´ ì˜¤ë””ì˜¤ ì„¤ì • ì •ë¦¬ ì¤‘...')
        
        // ScriptProcessorNode ì •ë¦¬
        if (processorRef.current) {
          processorRef.current.disconnect()
          processorRef.current = null
        }
        
        // AnalyserNode ì •ë¦¬
        if (analyserRef.current) {
          if ((analyserRef.current as any).intervalId) {
            clearInterval((analyserRef.current as any).intervalId)
          }
          analyserRef.current.disconnect()
          analyserRef.current = null
        }
        
        // AudioStream ì •ë¦¬
        if (audioStreamRef.current) {
          audioStreamRef.current.getTracks().forEach(track => track.stop())
          audioStreamRef.current = null
        }
        
        // AudioContext ì •ë¦¬
        if (audioContextRef.current) {
          audioContextRef.current.close()
          audioContextRef.current = null
        }
        
        setProcessorActive(false)
        setAudioLevel(0)
        setVoiceDetected(false)
      }
      
      console.log('1ï¸âƒ£ ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­ ì¤‘...')
      // ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          sampleRate: 16000,
          channelCount: 1,
          echoCancellation: true,
          noiseSuppression: true
        }
      })
      
      console.log('âœ… ë§ˆì´í¬ ê¶Œí•œ í—ˆìš©ë¨!')
      console.log('2ï¸âƒ£ ìŠ¤íŠ¸ë¦¼ ì •ë³´ ë¶„ì„ ì¤‘...')
      console.log('í™œì„± íŠ¸ë™ ìˆ˜:', stream.getAudioTracks().length)
      
      stream.getAudioTracks().forEach((track, index) => {
        console.log(`íŠ¸ë™ ${index + 1}:`, {
          ë¼ë²¨: track.label,
          í™œì„±í™”: track.enabled,
          ì¤€ë¹„ìƒíƒœ: track.readyState,
          ì„¤ì •: track.getSettings()
        })
      })
      
      audioStreamRef.current = stream

      console.log('3ï¸âƒ£ AudioContext ìƒì„± ì¤‘...')
      // AudioContext ì„¤ì • (ë¸Œë¼ìš°ì € í˜¸í™˜ì„±)
      const AudioContextClass = window.AudioContext || (window as any).webkitAudioContext
      const audioContext = new AudioContextClass({
        sampleRate: 16000
      })
      
      console.log('AudioContext ìƒì„±ë¨, ìƒíƒœ:', audioContext.state)
      console.log('ìƒ˜í”Œë ˆì´íŠ¸:', audioContext.sampleRate)
      
      // AudioContextê°€ suspended ìƒíƒœë©´ resume
      if (audioContext.state === 'suspended') {
        console.log('4ï¸âƒ£ AudioContext í™œì„±í™” ì¤‘...')
        await audioContext.resume()
        console.log('AudioContext í™œì„±í™”ë¨, í˜„ì¬ ìƒíƒœ:', audioContext.state)
      }
      
      audioContextRef.current = audioContext

      console.log('5ï¸âƒ£ ì˜¤ë””ì˜¤ ë…¸ë“œ ìƒì„± ì¤‘...')
      const source = audioContext.createMediaStreamSource(stream)
      console.log('MediaStreamSource ìƒì„±ë¨')
      
      // AnalyserNode ì‚¬ìš© (UI ë ˆë²¨ í‘œì‹œìš©)
      const analyser = audioContext.createAnalyser()
      analyser.fftSize = 2048
      analyser.smoothingTimeConstant = 0.3
      analyserRef.current = analyser
      console.log('AnalyserNode ìƒì„±ë¨ (fftSize: 2048) - UI ë ˆë²¨ í‘œì‹œìš©')

      console.log('6ï¸âƒ£ ì‹¤ì œ PCM ì˜¤ë””ì˜¤ ìº¡ì²˜ìš© ScriptProcessorNode ì„¤ì • ì¤‘...')
      
      // ScriptProcessorNodeë¡œ RAW PCM ë°ì´í„° ìº¡ì²˜ (Gemini ìš”êµ¬ì‚¬í•­)
      const processor = audioContext.createScriptProcessor(4096, 1, 1)
      processorRef.current = processor
      console.log('âœ… ScriptProcessorNode ìƒì„±ë¨ (RAW PCM ìº¡ì²˜ìš©)')

      let audioSendCount = 0
      let processorCallCount = 0
      
      processor.onaudioprocess = (event) => {
        processorCallCount++
        
        // ì²˜ìŒ ëª‡ ë²ˆì€ ë¡œê·¸ ì¶œë ¥
        if (processorCallCount <= 5) {
          console.log(`ğŸ“Š PCM í”„ë¡œì„¸ì„œ í˜¸ì¶œ #${processorCallCount}`)
        }
        
        const inputBuffer = event.inputBuffer.getChannelData(0)
        
        // ì‹¤ì‹œê°„ìœ¼ë¡œ Geminiì— PCM ë°ì´í„° ì „ì†¡
        if (isRecording && sessionRef.current) {
          // RMS ë ˆë²¨ ê³„ì‚° (ìŒì„± ê°ì§€ìš©)
          let sum = 0
          for (let i = 0; i < inputBuffer.length; i++) {
            sum += inputBuffer[i] * inputBuffer[i]
          }
          const rmsLevel = Math.sqrt(sum / inputBuffer.length)
          
          // ì¼ì • ë ˆë²¨ ì´ìƒì¼ ë•Œë§Œ ì „ì†¡ (ë…¸ì´ì¦ˆ í•„í„°ë§)
          if (rmsLevel > 0.01) {
            audioSendCount++
            console.log(`ğŸ¤ PCM ë°ì´í„° ì „ì†¡ #${audioSendCount}, RMS: ${rmsLevel.toFixed(4)}`)
            
            // Float32ë¥¼ Int16 PCMìœ¼ë¡œ ë³€í™˜
            const pcmData = float32ToInt16(inputBuffer)
            
            // Gemini Live APIì— RAW PCM ë°ì´í„° ì „ì†¡
            sendPCMToGemini(pcmData)
          }
        }
      }
      
      console.log('7ï¸âƒ£ UIìš© ì˜¤ë””ì˜¤ ë¶„ì„ íƒ€ì´ë¨¸ ì„¤ì • ì¤‘...')
      
      // setIntervalì„ ì‚¬ìš©í•˜ì—¬ ì£¼ê¸°ì ìœ¼ë¡œ ì˜¤ë””ì˜¤ ë ˆë²¨ í™•ì¸ (UIìš©)
      const audioAnalysisInterval = setInterval(() => {
        if (!analyser || !audioStreamRef.current) {
          console.log('âš ï¸ ë¶„ì„ ì¤‘ë‹¨: analyser ë˜ëŠ” streamì´ ì—†ìŒ')
          return
        }
        
        processorCallCount++
        
        // í”„ë¡œì„¸ì„œê°€ í™œì„±í™”ë˜ì—ˆìŒì„ UIì— í‘œì‹œ
        if (processorCallCount === 1) {
          setProcessorActive(true)
          console.log('ğŸ”„ ì˜¤ë””ì˜¤ ë¶„ì„ê¸° ì‹œì‘ë¨!')
        }
        
        // ì²˜ìŒ ëª‡ ë²ˆì€ ë¡œê·¸ ì¶œë ¥
        if (processorCallCount <= 5) {
          console.log(`ğŸ“Š ì˜¤ë””ì˜¤ ë¶„ì„ #${processorCallCount}`)
        }
        
        // ì£¼íŒŒìˆ˜ ë„ë©”ì¸ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        const bufferLength = analyser.frequencyBinCount
        const dataArray = new Uint8Array(bufferLength)
        analyser.getByteFrequencyData(dataArray)
        
        // í‰ê·  ë ˆë²¨ ê³„ì‚°
        const sum = dataArray.reduce((a, b) => a + b)
        const average = sum / bufferLength
        const max = Math.max(...dataArray)
        
        // 0-255 ë²”ìœ„ë¥¼ 0-1 ë²”ìœ„ë¡œ ì •ê·œí™”
        const currentAudioLevel = average / 255
        
        // ì²˜ìŒ ëª‡ ë²ˆì€ ë¬´ì¡°ê±´ ë¡œê·¸ ì¶œë ¥ (ë””ë²„ê¹…ìš©)
        if (processorCallCount <= 10) {
          console.log(`ğŸ“ˆ ì˜¤ë””ì˜¤ ë ˆë²¨ #${processorCallCount}: í‰ê· =${average.toFixed(2)}, ìµœëŒ€=${max}, ì •ê·œí™”=${currentAudioLevel.toFixed(6)}`)
        }
        
        // UI ì—…ë°ì´íŠ¸ (ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ë ˆë²¨ í‘œì‹œ)
        setAudioLevel(currentAudioLevel)
        
        // ìŒì„± ê°ì§€ ìƒíƒœ ì—…ë°ì´íŠ¸ (UIìš©)
        if (currentAudioLevel > 0.02) {
          setVoiceDetected(true)
          // ìŒì„± ê°ì§€ ìƒíƒœë¥¼ ì ì‹œ ìœ ì§€
          setTimeout(() => setVoiceDetected(false), 500)
        }
        
      }, 50) // 50msë§ˆë‹¤ ë¶„ì„ (20fps)
      
      // interval IDë¥¼ ì €ì¥í•˜ì—¬ ë‚˜ì¤‘ì— ì •ë¦¬í•  ìˆ˜ ìˆë„ë¡
      ;(analyser as any).intervalId = audioAnalysisInterval

      console.log('8ï¸âƒ£ ì˜¤ë””ì˜¤ ë…¸ë“œ ì—°ê²° ì¤‘...')
      source.connect(analyser) // UIìš© ë ˆë²¨ í‘œì‹œ
      source.connect(processor) // PCM ë°ì´í„° ìº¡ì²˜
      // destinationì—ëŠ” ì—°ê²°í•˜ì§€ ì•ŠìŒ (í”¼ë“œë°± ë°©ì§€)
      
      // í”„ë¡œì„¸ì„œê°€ í™œì„±í™”ë˜ì—ˆìŒì„ í‘œì‹œ
      setProcessorActive(true)
      
      console.log('âœ… ì˜¤ë””ì˜¤ ë…¸ë“œ ì—°ê²° ì™„ë£Œ!')
      console.log('âœ… ë§ˆì´í¬ ì„¤ì • ì™„ë£Œ!')
      console.log('ğŸ™ï¸ =================================')

    } catch (error) {
      console.log('âŒ =================================')
      console.error('âŒ ì˜¤ë””ì˜¤ ì„¤ì • ì˜¤ë¥˜:', error)
      console.error('ì—ëŸ¬ ì´ë¦„:', error.name)
      console.error('ì—ëŸ¬ ë©”ì‹œì§€:', error.message)
      console.log('âŒ =================================')
      
      setConnectionStatus('ë§ˆì´í¬ ì ‘ê·¼ ì‹¤íŒ¨: ' + error.message)
      
      // êµ¬ì²´ì ì¸ ì˜¤ë¥˜ ë©”ì‹œì§€ í‘œì‹œ
      if (error.name === 'NotAllowedError') {
        setConnectionStatus('ë§ˆì´í¬ ê¶Œí•œì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì—ì„œ ë§ˆì´í¬ ê¶Œí•œì„ í—ˆìš©í•´ì£¼ì„¸ìš”.')
      } else if (error.name === 'NotFoundError') {
        setConnectionStatus('ë§ˆì´í¬ ì¥ì¹˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
      }
    }
  }

  // Float32Arrayë¥¼ Int16Arrayë¡œ ë³€í™˜
  const float32ToInt16 = (float32Array: Float32Array): Int16Array => {
    const int16Array = new Int16Array(float32Array.length)
    for (let i = 0; i < float32Array.length; i++) {
      const val = Math.max(-1, Math.min(1, float32Array[i]))
      int16Array[i] = val < 0 ? val * 0x8000 : val * 0x7FFF
    }
    return int16Array
  }

  // RAW PCM ë°ì´í„°ë¥¼ Gemini Live APIì— ì „ì†¡ (ì˜¬ë°”ë¥¸ í˜•ì‹)
  const sendPCMToGemini = async (pcmData: Int16Array) => {
    try {
      // Int16Arrayë¥¼ Uint8Arrayë¡œ ë³€í™˜ (ë°”ì´íŠ¸ ë‹¨ìœ„)
      const bytes = new Uint8Array(pcmData.buffer)
      
      // Base64 ì¸ì½”ë”© (ì²­í¬ ë‹¨ìœ„ë¡œ ì²˜ë¦¬í•˜ì—¬ ë¸Œë¼ìš°ì € í˜¸í™˜ì„± ê°œì„ )
      let base64Audio = ''
      const chunkSize = 1024
      for (let i = 0; i < bytes.length; i += chunkSize) {
        const chunk = bytes.slice(i, i + chunkSize)
        base64Audio += btoa(String.fromCharCode.apply(null, Array.from(chunk)))
      }
      
      console.log(`ğŸ“¤ RAW PCM ë°ì´í„° Gemini ì „ì†¡: ${pcmData.length} samples, ${bytes.length} bytes`)
      
      if (sessionRef.current) {
        await sessionRef.current.sendRealtimeInput({
          audio: {
            data: base64Audio,
            mimeType: "audio/pcm;rate=16000" // ì˜¬ë°”ë¥¸ PCM í˜•ì‹!
          }
        })
        console.log(`âœ… PCM ë°ì´í„° ì „ì†¡ ì„±ê³µ!`)
      } else {
        console.log(`âŒ Gemini ì„¸ì…˜ì´ ì—†ì–´ì„œ PCM ì „ì†¡ ì‹¤íŒ¨`)
      }
      
    } catch (error) {
      console.error('âŒ PCM ë°ì´í„° ì „ì†¡ ì‹¤íŒ¨:', error)
    }
  }


  const handleGeminiMessage = useCallback((message: any) => {
    console.log('Gemini ì‘ë‹µ:', message)
    
    // ì„¤ì • ì™„ë£Œ
    if (message.setupComplete) {
      console.log('Gemini Live ì„¤ì • ì™„ë£Œ! ì´ì œ ìˆ˜ë™ìœ¼ë¡œ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.')
      return
    }
    
    // ì„œë²„ ì‘ë‹µ ì²˜ë¦¬ (ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°ìš©)
    if (message.serverContent) {
      const content = message.serverContent
      
      // ì…ë ¥ ì „ì‚¬ (ì‚¬ìš©ì ìŒì„± â†’ í…ìŠ¤íŠ¸)
      if (content.inputTranscription) {
        console.log('ì‚¬ìš©ì ìŒì„± ì „ì‚¬:', content.inputTranscription.text)
        const userMessage: Conversation = {
          role: 'user',
          content: content.inputTranscription.text,
          timestamp: new Date()
        }
        setConversations(prev => [...prev, userMessage])
      }
      
      // í…ìŠ¤íŠ¸ ì‘ë‹µ ì²˜ë¦¬ (ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°)
      if (content.modelTurn && content.modelTurn.parts) {
        for (const part of content.modelTurn.parts) {
          if (part.text) {
            console.log('AI í…ìŠ¤íŠ¸ ì‘ë‹µ:', part.text)
            const assistantMessage: Conversation = {
              role: 'assistant',
              content: part.text,
              timestamp: new Date(),
              audioComplete: true
            }
            setConversations(prev => [...prev, assistantMessage])
            
            // ëŒ€í™” ì €ì¥
            onConversationSave('AI ì§ˆë¬¸', part.text).catch(console.error)
          }
          
          // ì˜¤ë””ì˜¤ ì‘ë‹µ ì²˜ë¦¬ (ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°)
          if (part.inlineData && part.inlineData.mimeType === 'audio/pcm') {
            console.log('AI ì˜¤ë””ì˜¤ ì‘ë‹µ ìˆ˜ì‹  (ì‹¤ì‹œê°„)')
            try {
              playAudioData(part.inlineData.data)
              setIsAISpeaking(true)
            } catch (error) {
              console.error('ì˜¤ë””ì˜¤ ì¬ìƒ ì˜¤ë¥˜:', error)
            }
          }
        }
      }
      
      // ì¶œë ¥ ì „ì‚¬ (AI ìŒì„± â†’ í…ìŠ¤íŠ¸)
      if (content.outputTranscription) {
        console.log('AI ìŒì„± ì „ì‚¬:', content.outputTranscription.text)
      }
      
      // í„´ ì™„ë£Œ ì²˜ë¦¬
      if (content.turnComplete) {
        console.log('í„´ ì™„ë£Œ')
        setIsAISpeaking(false)
      }
      
      // ì¸í„°ëŸ½íŠ¸ ì²˜ë¦¬
      if (content.interrupted) {
        console.log('AI ì‘ë‹µ ì¸í„°ëŸ½íŠ¸ë¨')
        setIsAISpeaking(false)
      }
    }
  }, [onConversationSave])

  const playAudioData = (audioData: number[] | string) => {
    if (!audioContextRef.current) return

    try {
      let int16Data: Int16Array

      if (typeof audioData === 'string') {
        // Base64 ë¬¸ìì—´ì¸ ê²½ìš°
        const binaryString = atob(audioData)
        const bytes = new Uint8Array(binaryString.length)
        for (let i = 0; i < binaryString.length; i++) {
          bytes[i] = binaryString.charCodeAt(i)
        }
        int16Data = new Int16Array(bytes.buffer)
      } else {
        // ìˆ«ì ë°°ì—´ì¸ ê²½ìš° (ê³µì‹ ì˜ˆì œ íŒ¨í„´)
        int16Data = new Int16Array(audioData)
      }
      
      // Int16 to Float32 ë³€í™˜
      const floatData = new Float32Array(int16Data.length)
      for (let i = 0; i < int16Data.length; i++) {
        floatData[i] = int16Data[i] / (int16Data[i] < 0 ? 0x8000 : 0x7FFF)
      }
      
      // ì˜¤ë””ì˜¤ ë²„í¼ ìƒì„± ë° ì¬ìƒ (24kHz - ê³µì‹ ì˜ˆì œì™€ ë™ì¼)
      const audioContext = audioContextRef.current
      const audioBuffer = audioContext.createBuffer(1, floatData.length, 24000)
      audioBuffer.getChannelData(0).set(floatData)

      const source = audioContext.createBufferSource()
      source.buffer = audioBuffer
      source.connect(audioContext.destination)
      source.start()
      
      source.onended = () => {
        setIsAISpeaking(false)
        console.log('ì˜¤ë””ì˜¤ ì¬ìƒ ì™„ë£Œ')
      }

      console.log('ì˜¤ë””ì˜¤ ì¬ìƒ ì‹œì‘ë¨, ì§€ì†ì‹œê°„:', audioBuffer.duration, 'ì´ˆ')
    } catch (error) {
      console.error('ì˜¤ë””ì˜¤ ì¬ìƒ ì‹¤íŒ¨:', error)
      setIsAISpeaking(false)
    }
  }

  const startRecording = async () => {
    if (!isConnected) {
      console.log('ì—°ê²°ë˜ì§€ ì•ŠìŒ, ë…¹ìŒ ì‹œì‘ ë¶ˆê°€')
      return
    }
    
    console.log('ğŸ”´ ë…¹ìŒ ì‹œì‘ ë²„íŠ¼ í´ë¦­ë¨')
    
    try {
      // ì˜¤ë””ì˜¤ ìº¡ì²˜ ì„¤ì • (ë§¤ë²ˆ ìƒˆë¡œ ì„¤ì •)
      console.log('ğŸ™ï¸ ë…¹ìŒ ì‹œì‘ ì „ ì˜¤ë””ì˜¤ ìº¡ì²˜ ì„¤ì •...')
      await setupAudioCapture()
      
      // AudioContextê°€ suspended ìƒíƒœë©´ ì‚¬ìš©ì ì œìŠ¤ì²˜ë¡œ í™œì„±í™”
      if (audioContextRef.current && audioContextRef.current.state === 'suspended') {
        console.log('â¯ï¸ ì‚¬ìš©ì ì œìŠ¤ì²˜ë¡œ AudioContext í™œì„±í™” ì¤‘...')
        try {
          await audioContextRef.current.resume()
          console.log('âœ… AudioContext í™œì„±í™”ë¨:', audioContextRef.current.state)
        } catch (error) {
          console.error('âŒ AudioContext í™œì„±í™” ì‹¤íŒ¨:', error)
        }
      }
      
      // ScriptProcessorNodeëŠ” ìë™ìœ¼ë¡œ ì‹œì‘ë¨ (ë³„ë„ ì‹œì‘ ëª…ë ¹ ë¶ˆí•„ìš”)
      console.log('ğŸ¬ PCM ë°ì´í„° ìº¡ì²˜ ì‹œì‘ë¨ (ìë™)')
      
      setIsRecording(true)
      setConnectionStatus('ğŸ¤ ì‹¤ì‹œê°„ ìŒì„± ë…¹ìŒ ì¤‘... Geminiê°€ ë“£ê³  ìˆìŠµë‹ˆë‹¤!')
      console.log('ğŸ™ï¸ ë…¹ìŒ ìƒíƒœ í™œì„±í™” ì™„ë£Œ')
      
    } catch (error) {
      console.error('âŒ ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨:', error)
      setConnectionStatus('ë…¹ìŒ ì‹œì‘ ì‹¤íŒ¨: ' + error.message)
    }
  }

  const stopRecording = () => {
    console.log('â¹ï¸ ë…¹ìŒ ì¤‘ë‹¨ ìš”ì²­ë¨')
    
    // ScriptProcessorNodeëŠ” ë…¹ìŒ ìƒíƒœ í”Œë˜ê·¸ë§Œ ë³€ê²½í•˜ë©´ ë¨
    setIsRecording(false)
    setConnectionStatus('ìŒì„± ì¸í„°ë·° ì¤€ë¹„ ì™„ë£Œ')
    console.log('ğŸ”‡ ë…¹ìŒ ìƒíƒœ ë¹„í™œì„±í™” ì™„ë£Œ (PCM ìº¡ì²˜ëŠ” ê³„ì† í™œì„±)')
  }

  const testMicrophone = async () => {
    // ê°€ì¥ ê¸°ë³¸ì ì¸ ë¡œê·¸ë¶€í„° ì‹œì‘
    console.log('ğŸš€ =================================')
    console.log('ğŸš€ ë§ˆì´í¬ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ í˜¸ì¶œë¨!')
    console.log('ğŸš€ =================================')
    
    try {
      // ë‹¨ê³„ë³„ ìƒì„¸ ë””ë²„ê¹…
      console.log('1ï¸âƒ£ ë¸Œë¼ìš°ì € API ì§€ì› í™•ì¸ ì¤‘...')
      if (!navigator.mediaDevices) {
        throw new Error('navigator.mediaDevices ì§€ì›ë˜ì§€ ì•ŠìŒ')
      }
      if (!navigator.mediaDevices.getUserMedia) {
        throw new Error('getUserMedia ì§€ì›ë˜ì§€ ì•ŠìŒ')
      }
      console.log('âœ… ë¸Œë¼ìš°ì € API ì§€ì› í™•ì¸ë¨')
      
      console.log('2ï¸âƒ£ ë³´ì•ˆ ì»¨í…ìŠ¤íŠ¸ í™•ì¸ ì¤‘...')
      console.log('í˜„ì¬ URL:', window.location.href)
      console.log('í”„ë¡œí† ì½œ:', window.location.protocol)
      console.log('ë³´ì•ˆ ì»¨í…ìŠ¤íŠ¸:', window.isSecureContext)
      
      console.log('3ï¸âƒ£ ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­ ì¤‘... (íŒì—…ì´ ë‚˜íƒ€ë‚  ìˆ˜ ìˆìŠµë‹ˆë‹¤)')
      // ê°€ì¥ ê¸°ë³¸ì ì¸ ì„¤ì •ìœ¼ë¡œ ë¨¼ì € ì‹œë„
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: true
      })
      
      console.log('âœ… ë§ˆì´í¬ ê¶Œí•œ í—ˆìš©ë¨!')
      console.log('4ï¸âƒ£ ìŠ¤íŠ¸ë¦¼ ì •ë³´ ë¶„ì„ ì¤‘...')
      console.log('ì´ ì˜¤ë””ì˜¤ íŠ¸ë™ ìˆ˜:', stream.getAudioTracks().length)
      
      stream.getAudioTracks().forEach((track, index) => {
        console.log(`íŠ¸ë™ ${index + 1}:`, {
          ë¼ë²¨: track.label,
          í™œì„±í™”: track.enabled,
          ì¤€ë¹„ìƒíƒœ: track.readyState,
          ì¢…ë¥˜: track.kind,
          ì„¤ì •: track.getSettings()
        })
      })
      
      console.log('5ï¸âƒ£ AudioContext ìƒì„± ì¤‘...')
      const AudioContextClass = window.AudioContext || (window as any).webkitAudioContext
      if (!AudioContextClass) {
        throw new Error('AudioContextê°€ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤')
      }
      
      const testContext = new AudioContextClass()
      console.log('AudioContext ìƒì„±ë¨, ì´ˆê¸° ìƒíƒœ:', testContext.state)
      console.log('ìƒ˜í”Œë ˆì´íŠ¸:', testContext.sampleRate)
      
      if (testContext.state === 'suspended') {
        console.log('6ï¸âƒ£ AudioContext í™œì„±í™” ì¤‘...')
        await testContext.resume()
        console.log('AudioContext í™œì„±í™”ë¨, í˜„ì¬ ìƒíƒœ:', testContext.state)
      }
      
      console.log('7ï¸âƒ£ ì˜¤ë””ì˜¤ ë…¸ë“œ ìƒì„± ì¤‘...')
      const source = testContext.createMediaStreamSource(stream)
      console.log('MediaStreamSource ìƒì„±ë¨')
      
      const analyser = testContext.createAnalyser()
      analyser.fftSize = 256
      console.log('AnalyserNode ìƒì„±ë¨')
      
      source.connect(analyser)
      console.log('ë…¸ë“œ ì—°ê²° ì™„ë£Œ')
      
      console.log('8ï¸âƒ£ 10ì´ˆê°„ ë§ˆì´í¬ ë ˆë²¨ ì¸¡ì • ì‹œì‘...')
      const bufferLength = analyser.frequencyBinCount
      const dataArray = new Uint8Array(bufferLength)
      
      let measurementCount = 0
      const maxMeasurements = 50 // 10ì´ˆê°„ (200ms ê°„ê²©)
      
      const measureInterval = setInterval(() => {
        analyser.getByteFrequencyData(dataArray)
        const average = dataArray.reduce((a, b) => a + b) / bufferLength
        const max = Math.max(...dataArray)
        
        measurementCount++
        console.log(`ğŸ“Š ì¸¡ì • #${measurementCount}/50: í‰ê· =${average.toFixed(2)}, ìµœëŒ€=${max}`)
        
        if (measurementCount >= maxMeasurements) {
          console.log('9ï¸âƒ£ í…ŒìŠ¤íŠ¸ ì •ë¦¬ ì¤‘...')
          clearInterval(measureInterval)
          source.disconnect()
          stream.getTracks().forEach(track => {
            console.log(`íŠ¸ë™ ${track.label} ì •ì§€ ì¤‘...`)
            track.stop()
          })
          testContext.close()
          console.log('âœ… ë§ˆì´í¬ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!')
          console.log('ğŸš€ =================================')
        }
      }, 200)
      
    } catch (error) {
      console.log('âŒ =================================')
      console.error('âŒ ë§ˆì´í¬ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨:', error)
      console.error('ì—ëŸ¬ ì´ë¦„:', error.name)
      console.error('ì—ëŸ¬ ë©”ì‹œì§€:', error.message)
      console.error('ì „ì²´ ì—ëŸ¬ ê°ì²´:', error)
      console.log('âŒ =================================')
      
      // íŠ¹ì • ì—ëŸ¬ì— ëŒ€í•œ ì¶”ê°€ ì •ë³´
      if (error.name === 'NotAllowedError') {
        console.error('ğŸš« ë§ˆì´í¬ ê¶Œí•œì´ ê±°ë¶€ë˜ì—ˆìŠµë‹ˆë‹¤. ë¸Œë¼ìš°ì € ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.')
      } else if (error.name === 'NotFoundError') {
        console.error('ğŸ¤ ë§ˆì´í¬ ì¥ì¹˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.')
      } else if (error.name === 'NotSupportedError') {
        console.error('ğŸŒ í˜„ì¬ ë¸Œë¼ìš°ì €ì—ì„œ ì§€ì›ë˜ì§€ ì•ŠëŠ” ê¸°ëŠ¥ì…ë‹ˆë‹¤.')
      }
    }
  }

  const sendTestMessage = async () => {
    if (!sessionRef.current) {
      console.log('ì„¸ì…˜ì´ ì—†ì–´ì„œ í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€ ì „ì†¡ ë¶ˆê°€')
      return
    }

    try {
      console.log('í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€ ì „ì†¡ ì¤‘...')
      setIsAISpeaking(true)
      
      // ë°°ì¹˜ ëª¨ë“œìš© ë³„ë„ í ì´ˆê¸°í™”
      const batchQueue: any[] = []
      let isWaiting = true
      
      // ì„ì‹œ ë©”ì‹œì§€ í•¸ë“¤ëŸ¬
      const originalOnMessage = sessionRef.current.onmessage
      sessionRef.current.onmessage = (message: any) => {
        console.log('ë°°ì¹˜ ëª¨ë“œ ë©”ì‹œì§€:', message)
        batchQueue.push(message)
        
        if (message.serverContent && message.serverContent.turnComplete) {
          isWaiting = false
        }
      }
      
      // í…ìŠ¤íŠ¸ ë©”ì‹œì§€ ì „ì†¡
      await sessionRef.current.sendClientContent({
        turns: [{ role: "user", parts: [{ text: "ì•ˆë…•í•˜ì„¸ìš”! ê°„ë‹¨í•œ ì¸ì‚¬ë§ì„ í•´ì£¼ì„¸ìš”." }] }],
        turnComplete: true
      })
      console.log('í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€ ì „ì†¡ ì™„ë£Œ, ì‘ë‹µ ëŒ€ê¸° ì¤‘...')

      // ì‘ë‹µ ëŒ€ê¸°
      while (isWaiting) {
        await new Promise(resolve => setTimeout(resolve, 100))
      }
      
      // ì›ë˜ í•¸ë“¤ëŸ¬ ë³µêµ¬
      sessionRef.current.onmessage = originalOnMessage
      
      console.log('ë°°ì¹˜ ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ, ì´ ë©”ì‹œì§€:', batchQueue.length)

      // ì‘ë‹µ ì²˜ë¦¬
      let combinedAudio: number[] = []
      for (const message of batchQueue) {
        if (message.data) {
          console.log('ì˜¤ë””ì˜¤ ë°ì´í„° ìˆ˜ì‹ , í¬ê¸°:', message.data.length)
          const binaryString = atob(message.data)
          const bytes = new Uint8Array(binaryString.length)
          for (let i = 0; i < binaryString.length; i++) {
            bytes[i] = binaryString.charCodeAt(i)
          }
          const int16Array = new Int16Array(bytes.buffer)
          combinedAudio = combinedAudio.concat(Array.from(int16Array))
        }
      }

      if (combinedAudio.length > 0) {
        console.log('ì˜¤ë””ì˜¤ ì¬ìƒ ì‹œì‘, ì „ì²´ í¬ê¸°:', combinedAudio.length)
        playAudioData(combinedAudio)
      } else {
        console.log('ì˜¤ë””ì˜¤ ë°ì´í„° ì—†ìŒ, í…ìŠ¤íŠ¸ë§Œ ì‘ë‹µë¨')
        setIsAISpeaking(false)
      }

    } catch (error) {
      console.error('í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€ ì „ì†¡ ì˜¤ë¥˜:', error)
      setIsAISpeaking(false)
    }
  }

  const disconnect = useCallback(async () => {
    console.log('Gemini Live ì—°ê²° í•´ì œ ì¤‘...')

    // Gemini Live ì„¸ì…˜ í•´ì œ
    if (sessionRef.current) {
      try {
        sessionRef.current.close()
      } catch (error) {
        console.error('Gemini Live ì„¸ì…˜ ì¢…ë£Œ ì˜¤ë¥˜:', error)
      }
      sessionRef.current = null
    }

    // ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ í•´ì œ
    if (audioStreamRef.current) {
      audioStreamRef.current.getTracks().forEach(track => track.stop())
      audioStreamRef.current = null
    }

    // AudioContext í•´ì œ
    if (audioContextRef.current) {
      audioContextRef.current.close()
      audioContextRef.current = null
    }


    // AnalyserNode í•´ì œ (interval ì •ë¦¬)
    if (analyserRef.current) {
      try {
        // interval ì •ë¦¬
        if ((analyserRef.current as any).intervalId) {
          clearInterval((analyserRef.current as any).intervalId)
        }
        analyserRef.current.disconnect()
      } catch (error) {
        console.error('AnalyserNode í•´ì œ ì˜¤ë¥˜:', error)
      }
      analyserRef.current = null
    }

    // ê¸°ì¡´ Processor í•´ì œ (í˜¸í™˜ì„±ìš©)
    if (processorRef.current) {
      try {
        processorRef.current.disconnect()
      } catch (error) {
        console.error('Processor í•´ì œ ì˜¤ë¥˜:', error)
      }
      processorRef.current = null
    }

    setIsConnected(false)
    setIsRecording(false)
    setIsAISpeaking(false)
    setProcessorActive(false)
    setAudioLevel(0)
    setVoiceDetected(false)
    setConnectionStatus('ì—°ê²° í•´ì œë¨')
  }, [])

  const isMobile = typeof window !== 'undefined' && navigator.userAgent.match(/iPhone|iPad|iPod|Android/i)

  return (
    <div className="bg-white rounded-lg shadow-lg p-4 sm:p-6">
      <div className="mb-4 sm:mb-6">
        <h3 className="text-lg sm:text-xl font-semibold text-gray-800 mb-2">
          ğŸ¤ Gemini Live ì‹¤ì‹œê°„ ìŒì„± ì¸í„°ë·°
        </h3>
        <p className="text-sm sm:text-base text-gray-600 mb-2">{connectionStatus}</p>
        <p className="text-xs text-gray-500">
          Googleì˜ ìµœì‹  Gemini 2.5 Flash Native Audio Dialog ëª¨ë¸ê³¼ ì‹¤ì‹œê°„ ìŒì„± ëŒ€í™”ë¥¼ ë‚˜ëˆ„ì„¸ìš”
        </p>
        {isMobile && (
          <p className="text-xs sm:text-sm text-amber-600 mt-2">
            ğŸ“± ëª¨ë°”ì¼ í™˜ê²½ì…ë‹ˆë‹¤. Chrome ë˜ëŠ” Safari ë¸Œë¼ìš°ì € ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤.
          </p>
        )}
      </div>

      {/* ì—°ê²° ìƒíƒœ ë° ìŒì„± í™œë™ í‘œì‹œ */}
      <div className="flex flex-col items-center justify-center mb-4 sm:mb-6">
        <div className="flex items-center mb-3">
          <div className={`w-3 h-3 rounded-full mr-2 ${isConnected ? 'bg-green-500 animate-pulse' : 'bg-red-500'}`}></div>
          <span className="text-sm text-gray-600">
            {isConnected ? 'ì—°ê²°ë¨' : 'ì—°ê²° ì•ˆë¨'}
          </span>
        </div>
        
        {/* ìŒì„± í™œë™ í‘œì‹œ */}
        {(isRecording || processorActive) && (
          <div className="flex flex-col items-center space-y-2">
            {/* í”„ë¡œì„¸ì„œ ìƒíƒœ í‘œì‹œ */}
            <div className={`px-3 py-1 rounded-full text-xs font-medium ${
              processorActive 
                ? 'bg-blue-100 text-blue-800' 
                : 'bg-red-100 text-red-800'
            }`}>
              {processorActive ? 'ğŸ”„ ì˜¤ë””ì˜¤ í”„ë¡œì„¸ì„œ í™œì„±' : 'âŒ ì˜¤ë””ì˜¤ í”„ë¡œì„¸ì„œ ë¹„í™œì„±'}
            </div>
            
            {processorActive && (
              <>
                <div className="flex items-center space-x-3">
                  <span className="text-xs text-gray-500">ë§ˆì´í¬ ë ˆë²¨:</span>
                  <div className="w-32 h-2 bg-gray-200 rounded-full overflow-hidden">
                    <div 
                      className={`h-full transition-all duration-100 ${
                        voiceDetected ? 'bg-green-500' : 'bg-blue-400'
                      }`}
                      style={{ width: `${Math.min(100, audioLevel * 1000)}%` }}
                    ></div>
                  </div>
                  <span className="text-xs text-gray-500">
                    {(audioLevel * 100).toFixed(1)}%
                  </span>
                </div>
                
                <div className={`px-3 py-1 rounded-full text-xs font-medium ${
                  voiceDetected 
                    ? 'bg-green-100 text-green-800' 
                    : 'bg-gray-100 text-gray-600'
                }`}>
                  {isRecording 
                    ? (voiceDetected ? 'ğŸ¤ ìŒì„± ê°ì§€ë¨ (Geminië¡œ ì „ì†¡ ì¤‘)' : 'ğŸ”‡ ëŒ€ê¸° ì¤‘')
                    : 'â¸ï¸ ë…¹ìŒ ì¤‘ì§€ ìƒíƒœ'
                  }
                </div>
              </>
            )}
          </div>
        )}
      </div>

      {/* ìŒì„± ì¸í„°ë·° ì»¨íŠ¸ë¡¤ */}
      <div className="flex flex-col items-center gap-4 mb-6">
        {!isConnected ? (
          <button
            onClick={connectToGemini}
            className="bg-blue-600 hover:bg-blue-700 text-white font-bold py-3 px-6 rounded-lg text-lg transition-colors"
          >
            ğŸ¤ Gemini Live ì—°ê²°
          </button>
        ) : (
          <div className="flex flex-col gap-3">
            {/* ë§ˆì´í¬ í…ŒìŠ¤íŠ¸ ë²„íŠ¼ */}
            <button
              onClick={testMicrophone}
              className="bg-orange-600 hover:bg-orange-700 text-white font-bold py-2 px-4 rounded-lg transition-colors"
            >
              ğŸ” ë§ˆì´í¬ í…ŒìŠ¤íŠ¸ (F12 ì½˜ì†” í•„ìˆ˜ í™•ì¸!)
            </button>
            
            {/* í…ìŠ¤íŠ¸ í…ŒìŠ¤íŠ¸ ë²„íŠ¼ */}
            <button
              onClick={sendTestMessage}
              disabled={isAISpeaking}
              className="bg-purple-600 hover:bg-purple-700 disabled:bg-purple-400 text-white font-bold py-2 px-4 rounded-lg transition-colors"
            >
              ğŸ’¬ í…ìŠ¤íŠ¸ ë©”ì‹œì§€ í…ŒìŠ¤íŠ¸ (AIê°€ ìŒì„±ìœ¼ë¡œ ì‘ë‹µ)
            </button>
            
            {/* ìŒì„± ë…¹ìŒ ì»¨íŠ¸ë¡¤ */}
            <div className="flex gap-4">
              <button
                onClick={startRecording}
                disabled={isRecording || isAISpeaking}
                className={`font-bold py-3 px-6 rounded-lg text-lg transition-colors ${
                  isRecording 
                    ? 'bg-red-600 text-white cursor-not-allowed' 
                    : 'bg-green-600 hover:bg-green-700 text-white'
                }`}
              >
                {isRecording ? 'ğŸ”´ ë…¹ìŒ ì¤‘...' : 'ğŸ™ï¸ ìŒì„± ë…¹ìŒ ì‹œì‘'}
              </button>
              <button
                onClick={stopRecording}
                disabled={!isRecording}
                className="bg-gray-600 hover:bg-gray-700 disabled:bg-gray-400 text-white font-bold py-3 px-6 rounded-lg text-lg transition-colors"
              >
                â¹ï¸ ë…¹ìŒ ì¤‘ë‹¨
              </button>
            </div>
          </div>
        )}
      </div>

      {/* AI ì‘ë‹µ ìƒíƒœ */}
      {isAISpeaking && (
        <div className="text-center mb-4">
          <div className="inline-flex items-center px-4 py-2 bg-blue-100 rounded-lg">
            <div className="animate-spin rounded-full h-4 w-4 border-b-2 border-blue-600 mr-2"></div>
            <span className="text-blue-800 text-sm">AIê°€ ì‘ë‹µ ì¤‘ì…ë‹ˆë‹¤...</span>
          </div>
        </div>
      )}

      {/* ëŒ€í™” ë‚´ìš© */}
      {conversations.length > 0 && (
        <div className="bg-gray-50 rounded-lg p-4 max-h-60 overflow-y-auto">
          <h4 className="font-semibold text-gray-700 mb-3">ì‹¤ì‹œê°„ ëŒ€í™” ë‚´ìš©</h4>
          <div className="space-y-3">
            {conversations.map((conv, index) => (
              <div key={index} className={`flex ${conv.role === 'user' ? 'justify-end' : 'justify-start'}`}>
                <div className={`max-w-[80%] p-3 rounded-lg ${
                  conv.role === 'user' 
                    ? 'bg-blue-600 text-white' 
                    : 'bg-white text-gray-800 border'
                }`}>
                  <p className="text-sm">{conv.content}</p>
                  <p className="text-xs opacity-70 mt-1">
                    {conv.timestamp.toLocaleTimeString()}
                  </p>
                </div>
              </div>
            ))}
          </div>
        </div>
      )}

      {/* ë„ì›€ë§ */}
      <div className="mt-6 text-xs text-gray-500">
        <p className="mb-2">ğŸ’¡ ë¬¸ì œ í•´ê²° ê°€ì´ë“œ:</p>
        <ul className="list-disc list-inside space-y-1 ml-2">
          <li>â€¢ <strong>1ë‹¨ê³„</strong>: "Gemini Live ì—°ê²°" â†’ ì´ˆë¡ë¶ˆ í™•ì¸</li>
          <li>â€¢ <strong>2ë‹¨ê³„</strong>: "ë§ˆì´í¬ í…ŒìŠ¤íŠ¸" â†’ ì½˜ì†”ì—ì„œ ë§ˆì´í¬ ë ˆë²¨ ìˆ«ì í™•ì¸</li>
          <li>â€¢ <strong>3ë‹¨ê³„</strong>: "í…ìŠ¤íŠ¸ ë©”ì‹œì§€ í…ŒìŠ¤íŠ¸" â†’ AI ìŒì„± ë‚˜ì˜¤ëŠ”ì§€ í™•ì¸</li>
          <li>â€¢ <strong>4ë‹¨ê³„</strong>: "ìŒì„± ë…¹ìŒ ì‹œì‘" â†’ "ì˜¤ë””ì˜¤ í”„ë¡œì„¸ì„œ í™œì„±" íŒŒë€ìƒ‰ í‘œì‹œ í™•ì¸</li>
          <li>â€¢ <strong>5ë‹¨ê³„</strong>: ë§í•˜ê¸° â†’ ë§ˆì´í¬ ë ˆë²¨ ë°” ì›€ì§ì´ê³  "ìŒì„± ê°ì§€ë¨" ì´ˆë¡ìƒ‰ í‘œì‹œ í™•ì¸</li>
          <li>â€¢ ë§ˆì´í¬ ê¶Œí•œ í—ˆìš© í•„ìš” / ì½˜ì†” ë¡œê·¸ì—ì„œ "ğŸ“ˆ ì˜¤ë””ì˜¤ ë ˆë²¨" ë° "ğŸ¤ ìŒì„± ê°ì§€ë¨" í™•ì¸</li>
          <li>â€¢ í”„ë¡œì„¸ì„œê°€ ë¹„í™œì„±ì´ë©´ AudioContext ë¬¸ì œ / ë¬¸ì œ ì‹œ: í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨ í›„ ë‹¤ì‹œ ì‹œë„</li>
        </ul>
      </div>
    </div>
  )
}